{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entries\n",
    "\n",
    "1. Historical statistics of direct confrontation (team 1 vs team 2)\n",
    "2. Statistics of *N* previous matches for each team\n",
    "3. Home player or away player\n",
    "4. Current points on championship\n",
    "5. Match day matters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from db.database import DAO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dao = DAO()\n",
    "matches_collection = dao.matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5ac952926b5b9e2af46c59ef'),\n",
      " 'arbiter': 'Leonardo Gaciba da Silva',\n",
      " 'away_team': 'Santos',\n",
      " 'cards': [{'player': 'Alex Sandro', 'team': 'SAN', 'type': 'yellow'},\n",
      "           {'player': 'Zé Eduardo', 'team': 'SAN', 'type': 'yellow'},\n",
      "           {'player': 'Herrera', 'team': 'BOT', 'type': 'yellow'},\n",
      "           {'player': 'Wesley', 'team': 'SAN', 'type': 'yellow'},\n",
      "           {'player': 'Alex Sandro', 'team': 'SAN', 'type': 'red'}],\n",
      " 'coaches': {'away_team': 'Dorival Júnior', 'home_team': 'Joel Santana'},\n",
      " 'home_team': 'Botafogo',\n",
      " 'location': {'city': 'Brasil, Rio de Janeiro, RJ', 'stadium': 'Engenhão'},\n",
      " 'players': {'away_team': [{'name': 'Felipe Garcia', 'position': 'GOL'},\n",
      "                           {'name': 'Bruno Aguiar', 'position': 'ZAD'},\n",
      "                           {'name': 'Durval', 'position': 'ZAE'},\n",
      "                           {'name': 'Maranhão', 'position': 'LAD'},\n",
      "                           {'name': 'Alex Sandro', 'position': 'LAE'},\n",
      "                           {'name': 'Madson', 'position': 'MEC'},\n",
      "                           {'name': 'Breitner', 'position': 'MEC'},\n",
      "                           {'name': 'Wesley', 'position': 'VOL'},\n",
      "                           {'name': 'Marquinhos', 'position': 'MEC'},\n",
      "                           {'name': 'Roberto Brum', 'position': 'VOL'},\n",
      "                           {'name': 'Rodrigo Mancha', 'position': 'VOL'},\n",
      "                           {'name': 'Neymar', 'position': 'ATA'},\n",
      "                           {'name': 'Zé Eduardo', 'position': 'ATA'},\n",
      "                           {'name': 'André', 'position': 'ATA'}],\n",
      "             'home_team': [{'name': 'Jefferson', 'position': 'GOL'},\n",
      "                           {'name': 'Antônio Carlos', 'position': 'ZAD'},\n",
      "                           {'name': 'Fábio Ferreira', 'position': 'ZAE'},\n",
      "                           {'name': 'Alessandro', 'position': 'LAD'},\n",
      "                           {'name': 'Marcelo Cordeiro', 'position': 'LAE'},\n",
      "                           {'name': 'Somália', 'position': 'VOL'},\n",
      "                           {'name': 'Fahel', 'position': 'VOL'},\n",
      "                           {'name': 'Túlio Souza', 'position': 'VOL'},\n",
      "                           {'name': 'Edno', 'position': 'ATA'},\n",
      "                           {'name': 'Renato Cajá', 'position': 'MEC'},\n",
      "                           {'name': 'Caio', 'position': 'ATA'},\n",
      "                           {'name': 'Leandro Guerreiro', 'position': 'VOL'},\n",
      "                           {'name': 'Herrera', 'position': 'ATA'},\n",
      "                           {'name': 'Loco Abreu', 'position': 'ATA'}]},\n",
      " 'round': 1,\n",
      " 'schedule': {'date': '08/05/2010', 'day': 'Sábado', 'time': '18h30'},\n",
      " 'score': {'away_team': 3, 'home_team': 3},\n",
      " 'statistics': {'goals_away_team': 68,\n",
      "                'goals_home_team': 54,\n",
      "                'matches_same_score': 0,\n",
      "                'previous_draws': 17,\n",
      "                'previous_matches': 47,\n",
      "                'wins_away_team': 16,\n",
      "                'wins_home_team': 14},\n",
      " 'url': 'http://futpedia.globo.com/campeonato/campeonato-brasileiro/2010/05/08/botafogo-3-x-3-santos',\n",
      " 'year': 2010}\n"
     ]
    }
   ],
   "source": [
    "# Sample match for testing\n",
    "sample = matches_collection.find_one()\n",
    "pprint(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match Vectorizer\n",
    "Takes a match in the above format and extracts the most important characteristics in the following order:\n",
    "\n",
    "<ol>\n",
    "- Current match statistics\n",
    "<li> Home team score </li>\n",
    "<li> Away team score </li>\n",
    "\n",
    "- Statistics of all confronts of the teams\n",
    "<li> Goals by home team </li>\n",
    "<li> Goals by away team </li>\n",
    "<li> Number of victories of home team </li>\n",
    "<li> Number o victories of away team </li>\n",
    "<li> Number of draws </li>\n",
    "\n",
    "- Statistics of N previous games of each team\n",
    "<li> Balance of N last games of home team </li>\n",
    "<li> Balance of N last games of away team </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default match feature extractor. ht is home_team and at is away_team\n",
    "N = 4\n",
    "labels = ['ht_score', 'at_score', 'goals_ht', 'goals_at', 'wins_ht', 'wins_at', 'draws', \n",
    "          *(['sg_ht']*N), *(['sg_at']*N)]\n",
    "def vectorize_match(dao, match, N):\n",
    "    stats = match['statistics']\n",
    "    score = match['score']\n",
    "    home_team_last_sg = dao.get_last_N_balances(match['home_team'], N)\n",
    "    away_team_last_sg = dao.get_last_N_balances(match['away_team'], N)\n",
    "    return [\n",
    "            score['home_team'],\n",
    "            score['away_team'], \n",
    "            stats['goals_home_team'], \n",
    "            stats['goals_away_team'],\n",
    "            stats['wins_home_team'], \n",
    "            stats['wins_away_team'], \n",
    "            stats['previous_draws'], \n",
    "            *home_team_last_sg, \n",
    "            *away_team_last_sg\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ht_score</th>\n",
       "      <th>at_score</th>\n",
       "      <th>goals_ht</th>\n",
       "      <th>goals_at</th>\n",
       "      <th>wins_ht</th>\n",
       "      <th>wins_at</th>\n",
       "      <th>draws</th>\n",
       "      <th>sg_ht</th>\n",
       "      <th>sg_ht</th>\n",
       "      <th>sg_ht</th>\n",
       "      <th>sg_ht</th>\n",
       "      <th>sg_at</th>\n",
       "      <th>sg_at</th>\n",
       "      <th>sg_at</th>\n",
       "      <th>sg_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>80</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>62</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>97</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ht_score  at_score  goals_ht  goals_at  wins_ht  wins_at  draws  sg_ht  \\\n",
       "0         4         0        50        39       15        8     13     -1   \n",
       "1         1         0        48        35       16        9      8     -1   \n",
       "2         1         0        92        80       25       19     17      2   \n",
       "3         1         0        48        62       10       17     12      0   \n",
       "4         0         1        72        97       21       26     13     -1   \n",
       "\n",
       "   sg_ht  sg_ht  sg_ht  sg_at  sg_at  sg_at  sg_at  \n",
       "0      1      1      0     -2     -1      2      0  \n",
       "1      0      2     -2     -1      0     -2     -1  \n",
       "2     -2      0      0      1      1     -2      2  \n",
       "3     -1     -1      0      0      1      1      1  \n",
       "4      1      2      2      1      0      1      0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize matches from 2016\n",
    "matches = matches_collection.find({'year':2016})\n",
    "data = [vectorize_match(dao, match, N) for match in matches]\n",
    "data = pd.DataFrame(data=data, columns=labels)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ht_score</th>\n",
       "      <th>at_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ht_score  at_score\n",
       "0         4         0\n",
       "1         1         0\n",
       "2         1         0\n",
       "3         1         0\n",
       "4         0         1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting X and Y\n",
    "Y = data.iloc[:,:2]\n",
    "X = data.iloc[:,2:]\n",
    "Y.head() # Y.values to extract the matrix from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "xscaler = StandardScaler()\n",
    "yscaler = StandardScaler()\n",
    "X = xscaler.fit_transform(X)\n",
    "#Y = yscaler.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Perceptron ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the neural network\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=len(X_train[0]), activation='linear'))\n",
    "model.add(Dense(2, activation='selu'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='sgd', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. linear + sigmoid :69.74%\n",
    "2. linear + linear : 73.68\n",
    "3. softsign 69.74\n",
    "4. tanh 72.37 = elu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 272 samples, validate on 31 samples\n",
      "Epoch 1/150\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 3.6417 - binary_accuracy: 0.2151 - val_loss: 2.0277 - val_binary_accuracy: 0.2419\n",
      "Epoch 2/150\n",
      "272/272 [==============================] - 0s 285us/step - loss: 1.7855 - binary_accuracy: 0.3382 - val_loss: 1.4157 - val_binary_accuracy: 0.3065\n",
      "Epoch 3/150\n",
      "272/272 [==============================] - 0s 278us/step - loss: 1.3742 - binary_accuracy: 0.3640 - val_loss: 1.3420 - val_binary_accuracy: 0.2581\n",
      "Epoch 4/150\n",
      "272/272 [==============================] - 0s 273us/step - loss: 1.2577 - binary_accuracy: 0.3621 - val_loss: 1.2259 - val_binary_accuracy: 0.2903\n",
      "Epoch 5/150\n",
      "272/272 [==============================] - 0s 236us/step - loss: 1.2015 - binary_accuracy: 0.3401 - val_loss: 1.2143 - val_binary_accuracy: 0.2581\n",
      "Epoch 6/150\n",
      "272/272 [==============================] - 0s 261us/step - loss: 1.1921 - binary_accuracy: 0.3456 - val_loss: 1.2932 - val_binary_accuracy: 0.2581\n",
      "Epoch 7/150\n",
      "272/272 [==============================] - 0s 264us/step - loss: 1.1943 - binary_accuracy: 0.3290 - val_loss: 1.1914 - val_binary_accuracy: 0.2742\n",
      "Epoch 8/150\n",
      "272/272 [==============================] - 0s 333us/step - loss: 1.1801 - binary_accuracy: 0.3529 - val_loss: 1.2011 - val_binary_accuracy: 0.2581\n",
      "Epoch 9/150\n",
      "272/272 [==============================] - 0s 279us/step - loss: 1.1684 - binary_accuracy: 0.3382 - val_loss: 1.2086 - val_binary_accuracy: 0.2903\n",
      "Epoch 10/150\n",
      "272/272 [==============================] - 0s 301us/step - loss: 1.1791 - binary_accuracy: 0.3290 - val_loss: 1.2090 - val_binary_accuracy: 0.2581\n",
      "Epoch 11/150\n",
      "272/272 [==============================] - 0s 271us/step - loss: 1.1731 - binary_accuracy: 0.3327 - val_loss: 1.1399 - val_binary_accuracy: 0.2581\n",
      "Epoch 12/150\n",
      "272/272 [==============================] - 0s 311us/step - loss: 1.1642 - binary_accuracy: 0.3548 - val_loss: 1.1497 - val_binary_accuracy: 0.2742\n",
      "Epoch 13/150\n",
      "272/272 [==============================] - 0s 308us/step - loss: 1.1616 - binary_accuracy: 0.3401 - val_loss: 1.1512 - val_binary_accuracy: 0.2742\n",
      "Epoch 14/150\n",
      "272/272 [==============================] - 0s 320us/step - loss: 1.1557 - binary_accuracy: 0.3309 - val_loss: 1.1401 - val_binary_accuracy: 0.2742\n",
      "Epoch 15/150\n",
      "272/272 [==============================] - 0s 311us/step - loss: 1.1559 - binary_accuracy: 0.3511 - val_loss: 1.1549 - val_binary_accuracy: 0.2742\n",
      "Epoch 16/150\n",
      "272/272 [==============================] - 0s 304us/step - loss: 1.1611 - binary_accuracy: 0.3438 - val_loss: 1.1562 - val_binary_accuracy: 0.2581\n",
      "Epoch 17/150\n",
      "272/272 [==============================] - 0s 304us/step - loss: 1.1618 - binary_accuracy: 0.3364 - val_loss: 1.1669 - val_binary_accuracy: 0.2419\n",
      "Epoch 18/150\n",
      "272/272 [==============================] - 0s 263us/step - loss: 1.1540 - binary_accuracy: 0.3511 - val_loss: 1.1749 - val_binary_accuracy: 0.2903\n",
      "Epoch 19/150\n",
      "272/272 [==============================] - 0s 273us/step - loss: 1.1583 - binary_accuracy: 0.3474 - val_loss: 1.1994 - val_binary_accuracy: 0.2581\n",
      "Epoch 20/150\n",
      "272/272 [==============================] - 0s 327us/step - loss: 1.1442 - binary_accuracy: 0.3640 - val_loss: 1.1452 - val_binary_accuracy: 0.2742\n",
      "Epoch 21/150\n",
      "272/272 [==============================] - 0s 326us/step - loss: 1.1534 - binary_accuracy: 0.3548 - val_loss: 1.1857 - val_binary_accuracy: 0.2258\n",
      "Epoch 22/150\n",
      "272/272 [==============================] - 0s 251us/step - loss: 1.1604 - binary_accuracy: 0.3456 - val_loss: 1.1690 - val_binary_accuracy: 0.2419\n",
      "Epoch 23/150\n",
      "272/272 [==============================] - 0s 311us/step - loss: 1.1546 - binary_accuracy: 0.3548 - val_loss: 1.1211 - val_binary_accuracy: 0.2903\n",
      "Epoch 24/150\n",
      "272/272 [==============================] - 0s 289us/step - loss: 1.1523 - binary_accuracy: 0.3548 - val_loss: 1.1254 - val_binary_accuracy: 0.2903\n",
      "Epoch 25/150\n",
      "272/272 [==============================] - 0s 297us/step - loss: 1.1536 - binary_accuracy: 0.3511 - val_loss: 1.1393 - val_binary_accuracy: 0.2419\n",
      "Epoch 26/150\n",
      "272/272 [==============================] - 0s 272us/step - loss: 1.1485 - binary_accuracy: 0.3511 - val_loss: 1.1454 - val_binary_accuracy: 0.2581\n",
      "Epoch 27/150\n",
      "272/272 [==============================] - 0s 245us/step - loss: 1.1442 - binary_accuracy: 0.3382 - val_loss: 1.1824 - val_binary_accuracy: 0.2258\n",
      "Epoch 28/150\n",
      "272/272 [==============================] - 0s 247us/step - loss: 1.1501 - binary_accuracy: 0.3474 - val_loss: 1.1518 - val_binary_accuracy: 0.2258\n",
      "Epoch 29/150\n",
      "272/272 [==============================] - 0s 276us/step - loss: 1.1402 - binary_accuracy: 0.3585 - val_loss: 1.1471 - val_binary_accuracy: 0.2742\n",
      "Epoch 30/150\n",
      "272/272 [==============================] - 0s 273us/step - loss: 1.1461 - binary_accuracy: 0.3548 - val_loss: 1.1741 - val_binary_accuracy: 0.2419\n",
      "Epoch 31/150\n",
      "272/272 [==============================] - 0s 295us/step - loss: 1.1447 - binary_accuracy: 0.3511 - val_loss: 1.1597 - val_binary_accuracy: 0.2581\n",
      "Epoch 32/150\n",
      "272/272 [==============================] - 0s 271us/step - loss: 1.1375 - binary_accuracy: 0.3438 - val_loss: 1.1439 - val_binary_accuracy: 0.2742\n",
      "Epoch 33/150\n",
      "272/272 [==============================] - 0s 288us/step - loss: 1.1427 - binary_accuracy: 0.3456 - val_loss: 1.1407 - val_binary_accuracy: 0.2742\n",
      "Epoch 34/150\n",
      "272/272 [==============================] - 0s 290us/step - loss: 1.1400 - binary_accuracy: 0.3382 - val_loss: 1.1715 - val_binary_accuracy: 0.2258\n",
      "Epoch 35/150\n",
      "272/272 [==============================] - 0s 281us/step - loss: 1.1402 - binary_accuracy: 0.3419 - val_loss: 1.2264 - val_binary_accuracy: 0.3065\n",
      "Epoch 36/150\n",
      "272/272 [==============================] - 0s 295us/step - loss: 1.1411 - binary_accuracy: 0.3364 - val_loss: 1.1973 - val_binary_accuracy: 0.2581\n",
      "Epoch 37/150\n",
      "272/272 [==============================] - 0s 268us/step - loss: 1.1377 - binary_accuracy: 0.3309 - val_loss: 1.1755 - val_binary_accuracy: 0.2419\n",
      "Epoch 38/150\n",
      "272/272 [==============================] - 0s 247us/step - loss: 1.1370 - binary_accuracy: 0.3548 - val_loss: 1.2072 - val_binary_accuracy: 0.2419\n",
      "Epoch 39/150\n",
      "272/272 [==============================] - 0s 240us/step - loss: 1.1365 - binary_accuracy: 0.3401 - val_loss: 1.1612 - val_binary_accuracy: 0.2419\n",
      "Epoch 40/150\n",
      "272/272 [==============================] - 0s 305us/step - loss: 1.1367 - binary_accuracy: 0.3474 - val_loss: 1.1733 - val_binary_accuracy: 0.2742\n",
      "Epoch 41/150\n",
      "272/272 [==============================] - 0s 317us/step - loss: 1.1328 - binary_accuracy: 0.3474 - val_loss: 1.1683 - val_binary_accuracy: 0.2742\n",
      "Epoch 42/150\n",
      "272/272 [==============================] - 0s 309us/step - loss: 1.1278 - binary_accuracy: 0.3585 - val_loss: 1.2778 - val_binary_accuracy: 0.3065\n",
      "Epoch 43/150\n",
      "272/272 [==============================] - 0s 298us/step - loss: 1.1466 - binary_accuracy: 0.3456 - val_loss: 1.1655 - val_binary_accuracy: 0.2419\n",
      "Epoch 44/150\n",
      "272/272 [==============================] - 0s 251us/step - loss: 1.1322 - binary_accuracy: 0.3364 - val_loss: 1.1732 - val_binary_accuracy: 0.2258\n",
      "Epoch 45/150\n",
      "272/272 [==============================] - 0s 234us/step - loss: 1.1362 - binary_accuracy: 0.3438 - val_loss: 1.2287 - val_binary_accuracy: 0.2419\n",
      "Epoch 46/150\n",
      "272/272 [==============================] - 0s 205us/step - loss: 1.1350 - binary_accuracy: 0.3511 - val_loss: 1.1558 - val_binary_accuracy: 0.2581\n",
      "Epoch 47/150\n",
      "272/272 [==============================] - 0s 313us/step - loss: 1.1299 - binary_accuracy: 0.3603 - val_loss: 1.1629 - val_binary_accuracy: 0.2903\n",
      "Epoch 48/150\n",
      "272/272 [==============================] - 0s 241us/step - loss: 1.1223 - binary_accuracy: 0.3511 - val_loss: 1.2396 - val_binary_accuracy: 0.2903\n",
      "Epoch 49/150\n",
      "272/272 [==============================] - 0s 242us/step - loss: 1.1372 - binary_accuracy: 0.3493 - val_loss: 1.1663 - val_binary_accuracy: 0.2419\n",
      "Epoch 50/150\n",
      "272/272 [==============================] - 0s 262us/step - loss: 1.1312 - binary_accuracy: 0.3438 - val_loss: 1.1610 - val_binary_accuracy: 0.2742\n",
      "Epoch 51/150\n",
      "272/272 [==============================] - 0s 250us/step - loss: 1.1363 - binary_accuracy: 0.3419 - val_loss: 1.1395 - val_binary_accuracy: 0.2258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/150\n",
      "272/272 [==============================] - 0s 234us/step - loss: 1.1362 - binary_accuracy: 0.3474 - val_loss: 1.1198 - val_binary_accuracy: 0.2258\n",
      "Epoch 53/150\n",
      "272/272 [==============================] - 0s 297us/step - loss: 1.1317 - binary_accuracy: 0.3419 - val_loss: 1.1318 - val_binary_accuracy: 0.2581\n",
      "Epoch 54/150\n",
      "272/272 [==============================] - 0s 234us/step - loss: 1.1269 - binary_accuracy: 0.3640 - val_loss: 1.1437 - val_binary_accuracy: 0.2419\n",
      "Epoch 55/150\n",
      "272/272 [==============================] - 0s 246us/step - loss: 1.1281 - binary_accuracy: 0.3382 - val_loss: 1.1455 - val_binary_accuracy: 0.2581\n",
      "Epoch 56/150\n",
      "272/272 [==============================] - 0s 204us/step - loss: 1.1251 - binary_accuracy: 0.3511 - val_loss: 1.2998 - val_binary_accuracy: 0.2419\n",
      "Epoch 57/150\n",
      "272/272 [==============================] - 0s 276us/step - loss: 1.1422 - binary_accuracy: 0.3732 - val_loss: 1.1866 - val_binary_accuracy: 0.2581\n",
      "Epoch 58/150\n",
      "272/272 [==============================] - 0s 251us/step - loss: 1.1270 - binary_accuracy: 0.3621 - val_loss: 1.2245 - val_binary_accuracy: 0.2742\n",
      "Epoch 59/150\n",
      "272/272 [==============================] - 0s 264us/step - loss: 1.1301 - binary_accuracy: 0.3401 - val_loss: 1.1657 - val_binary_accuracy: 0.2581\n",
      "Epoch 60/150\n",
      "272/272 [==============================] - 0s 247us/step - loss: 1.1247 - binary_accuracy: 0.3695 - val_loss: 1.2039 - val_binary_accuracy: 0.2581\n",
      "Epoch 61/150\n",
      "272/272 [==============================] - 0s 209us/step - loss: 1.1275 - binary_accuracy: 0.3419 - val_loss: 1.1638 - val_binary_accuracy: 0.3065\n",
      "Epoch 62/150\n",
      "272/272 [==============================] - 0s 263us/step - loss: 1.1270 - binary_accuracy: 0.3382 - val_loss: 1.1295 - val_binary_accuracy: 0.2419\n",
      "Epoch 63/150\n",
      "272/272 [==============================] - 0s 259us/step - loss: 1.1310 - binary_accuracy: 0.3493 - val_loss: 1.1394 - val_binary_accuracy: 0.2419\n",
      "Epoch 64/150\n",
      "272/272 [==============================] - 0s 255us/step - loss: 1.1257 - binary_accuracy: 0.3401 - val_loss: 1.1328 - val_binary_accuracy: 0.2419\n",
      "Epoch 65/150\n",
      "272/272 [==============================] - 0s 222us/step - loss: 1.1246 - binary_accuracy: 0.3493 - val_loss: 1.1661 - val_binary_accuracy: 0.2742\n",
      "Epoch 66/150\n",
      "272/272 [==============================] - 0s 200us/step - loss: 1.1258 - binary_accuracy: 0.3548 - val_loss: 1.1648 - val_binary_accuracy: 0.2419\n",
      "Epoch 67/150\n",
      "272/272 [==============================] - 0s 250us/step - loss: 1.1291 - binary_accuracy: 0.3529 - val_loss: 1.1832 - val_binary_accuracy: 0.2742\n",
      "Epoch 68/150\n",
      "272/272 [==============================] - 0s 253us/step - loss: 1.1323 - binary_accuracy: 0.3493 - val_loss: 1.1409 - val_binary_accuracy: 0.2742\n",
      "Epoch 69/150\n",
      "272/272 [==============================] - 0s 231us/step - loss: 1.1331 - binary_accuracy: 0.3493 - val_loss: 1.2071 - val_binary_accuracy: 0.2742\n",
      "Epoch 70/150\n",
      "272/272 [==============================] - 0s 224us/step - loss: 1.1318 - binary_accuracy: 0.3419 - val_loss: 1.1326 - val_binary_accuracy: 0.2581\n",
      "Epoch 71/150\n",
      "272/272 [==============================] - 0s 245us/step - loss: 1.1259 - binary_accuracy: 0.3566 - val_loss: 1.1915 - val_binary_accuracy: 0.2742\n",
      "Epoch 72/150\n",
      "272/272 [==============================] - 0s 223us/step - loss: 1.1279 - binary_accuracy: 0.3474 - val_loss: 1.1500 - val_binary_accuracy: 0.2419\n",
      "Epoch 73/150\n",
      "272/272 [==============================] - 0s 245us/step - loss: 1.1289 - binary_accuracy: 0.3327 - val_loss: 1.1309 - val_binary_accuracy: 0.2742\n",
      "Epoch 74/150\n",
      "272/272 [==============================] - 0s 236us/step - loss: 1.1228 - binary_accuracy: 0.3658 - val_loss: 1.1261 - val_binary_accuracy: 0.2258\n",
      "Epoch 75/150\n",
      "272/272 [==============================] - 0s 244us/step - loss: 1.1281 - binary_accuracy: 0.3474 - val_loss: 1.1324 - val_binary_accuracy: 0.2419\n",
      "Epoch 76/150\n",
      "272/272 [==============================] - 0s 256us/step - loss: 1.1233 - binary_accuracy: 0.3493 - val_loss: 1.1209 - val_binary_accuracy: 0.2258\n",
      "Epoch 77/150\n",
      "272/272 [==============================] - 0s 260us/step - loss: 1.1222 - binary_accuracy: 0.3621 - val_loss: 1.1129 - val_binary_accuracy: 0.2419\n",
      "Epoch 78/150\n",
      "272/272 [==============================] - 0s 249us/step - loss: 1.1221 - binary_accuracy: 0.3511 - val_loss: 1.1400 - val_binary_accuracy: 0.2742\n",
      "Epoch 79/150\n",
      "272/272 [==============================] - 0s 237us/step - loss: 1.1198 - binary_accuracy: 0.3474 - val_loss: 1.2040 - val_binary_accuracy: 0.2581\n",
      "Epoch 80/150\n",
      "272/272 [==============================] - 0s 239us/step - loss: 1.1306 - binary_accuracy: 0.3566 - val_loss: 1.1695 - val_binary_accuracy: 0.2258\n",
      "Epoch 81/150\n",
      "272/272 [==============================] - 0s 236us/step - loss: 1.1214 - binary_accuracy: 0.3438 - val_loss: 1.1353 - val_binary_accuracy: 0.2258\n",
      "Epoch 82/150\n",
      "272/272 [==============================] - 0s 258us/step - loss: 1.1232 - binary_accuracy: 0.3474 - val_loss: 1.1237 - val_binary_accuracy: 0.2419\n",
      "Epoch 83/150\n",
      "272/272 [==============================] - 0s 269us/step - loss: 1.1276 - binary_accuracy: 0.3493 - val_loss: 1.1349 - val_binary_accuracy: 0.2419\n",
      "Epoch 84/150\n",
      "272/272 [==============================] - 0s 208us/step - loss: 1.1196 - binary_accuracy: 0.3529 - val_loss: 1.1410 - val_binary_accuracy: 0.2581\n",
      "Epoch 85/150\n",
      "272/272 [==============================] - 0s 206us/step - loss: 1.1253 - binary_accuracy: 0.3419 - val_loss: 1.1784 - val_binary_accuracy: 0.2742\n",
      "Epoch 86/150\n",
      "272/272 [==============================] - 0s 203us/step - loss: 1.1248 - binary_accuracy: 0.3511 - val_loss: 1.1320 - val_binary_accuracy: 0.2581\n",
      "Epoch 87/150\n",
      "272/272 [==============================] - 0s 244us/step - loss: 1.1193 - binary_accuracy: 0.3493 - val_loss: 1.1254 - val_binary_accuracy: 0.2258\n",
      "Epoch 88/150\n",
      "272/272 [==============================] - 0s 267us/step - loss: 1.1208 - binary_accuracy: 0.3456 - val_loss: 1.1149 - val_binary_accuracy: 0.2258\n",
      "Epoch 89/150\n",
      "272/272 [==============================] - 0s 259us/step - loss: 1.1209 - binary_accuracy: 0.3474 - val_loss: 1.1768 - val_binary_accuracy: 0.2419\n",
      "Epoch 90/150\n",
      "272/272 [==============================] - 0s 215us/step - loss: 1.1294 - binary_accuracy: 0.3603 - val_loss: 1.1437 - val_binary_accuracy: 0.2258\n",
      "Epoch 91/150\n",
      "272/272 [==============================] - 0s 208us/step - loss: 1.1249 - binary_accuracy: 0.3695 - val_loss: 1.1899 - val_binary_accuracy: 0.2097\n",
      "Epoch 92/150\n",
      "272/272 [==============================] - 0s 195us/step - loss: 1.1297 - binary_accuracy: 0.3529 - val_loss: 1.1940 - val_binary_accuracy: 0.2581\n",
      "Epoch 93/150\n",
      "272/272 [==============================] - 0s 269us/step - loss: 1.1205 - binary_accuracy: 0.3621 - val_loss: 1.1715 - val_binary_accuracy: 0.2258\n",
      "Epoch 94/150\n",
      "272/272 [==============================] - 0s 257us/step - loss: 1.1238 - binary_accuracy: 0.3474 - val_loss: 1.1705 - val_binary_accuracy: 0.2581\n",
      "Epoch 95/150\n",
      "272/272 [==============================] - 0s 208us/step - loss: 1.1319 - binary_accuracy: 0.3456 - val_loss: 1.1303 - val_binary_accuracy: 0.2581\n",
      "Epoch 96/150\n",
      "272/272 [==============================] - 0s 226us/step - loss: 1.1203 - binary_accuracy: 0.3474 - val_loss: 1.1442 - val_binary_accuracy: 0.2581\n",
      "Epoch 97/150\n",
      "272/272 [==============================] - 0s 273us/step - loss: 1.1194 - binary_accuracy: 0.3511 - val_loss: 1.1237 - val_binary_accuracy: 0.2419\n",
      "Epoch 98/150\n",
      "272/272 [==============================] - 0s 247us/step - loss: 1.1147 - binary_accuracy: 0.3493 - val_loss: 1.1207 - val_binary_accuracy: 0.2258\n",
      "Epoch 99/150\n",
      "272/272 [==============================] - 0s 262us/step - loss: 1.1159 - binary_accuracy: 0.3438 - val_loss: 1.1313 - val_binary_accuracy: 0.2097\n",
      "Epoch 100/150\n",
      "272/272 [==============================] - 0s 250us/step - loss: 1.1235 - binary_accuracy: 0.3548 - val_loss: 1.1345 - val_binary_accuracy: 0.2258\n",
      "Epoch 101/150\n",
      "272/272 [==============================] - 0s 197us/step - loss: 1.1198 - binary_accuracy: 0.3493 - val_loss: 1.1604 - val_binary_accuracy: 0.2581\n",
      "Epoch 102/150\n",
      "272/272 [==============================] - 0s 255us/step - loss: 1.1190 - binary_accuracy: 0.3566 - val_loss: 1.1431 - val_binary_accuracy: 0.2581\n",
      "Epoch 103/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/272 [==============================] - 0s 242us/step - loss: 1.1231 - binary_accuracy: 0.3548 - val_loss: 1.1483 - val_binary_accuracy: 0.3065\n",
      "Epoch 104/150\n",
      "272/272 [==============================] - 0s 241us/step - loss: 1.1183 - binary_accuracy: 0.3529 - val_loss: 1.1434 - val_binary_accuracy: 0.2581\n",
      "Epoch 105/150\n",
      "272/272 [==============================] - 0s 281us/step - loss: 1.1130 - binary_accuracy: 0.3493 - val_loss: 1.1500 - val_binary_accuracy: 0.2903\n",
      "Epoch 106/150\n",
      "272/272 [==============================] - 0s 205us/step - loss: 1.1188 - binary_accuracy: 0.3529 - val_loss: 1.1222 - val_binary_accuracy: 0.2258\n",
      "Epoch 107/150\n",
      "272/272 [==============================] - 0s 231us/step - loss: 1.1145 - binary_accuracy: 0.3456 - val_loss: 1.1481 - val_binary_accuracy: 0.2419\n",
      "Epoch 108/150\n",
      "272/272 [==============================] - 0s 267us/step - loss: 1.1192 - binary_accuracy: 0.3438 - val_loss: 1.1744 - val_binary_accuracy: 0.2258\n",
      "Epoch 109/150\n",
      "272/272 [==============================] - 0s 253us/step - loss: 1.1249 - binary_accuracy: 0.3548 - val_loss: 1.1513 - val_binary_accuracy: 0.2258\n",
      "Epoch 110/150\n",
      "272/272 [==============================] - 0s 242us/step - loss: 1.1185 - binary_accuracy: 0.3529 - val_loss: 1.1594 - val_binary_accuracy: 0.2419\n",
      "Epoch 111/150\n",
      "272/272 [==============================] - 0s 255us/step - loss: 1.1179 - binary_accuracy: 0.3493 - val_loss: 1.1456 - val_binary_accuracy: 0.2903\n",
      "Epoch 112/150\n",
      "272/272 [==============================] - 0s 247us/step - loss: 1.1210 - binary_accuracy: 0.3640 - val_loss: 1.2264 - val_binary_accuracy: 0.2419\n",
      "Epoch 113/150\n",
      "272/272 [==============================] - 0s 228us/step - loss: 1.1247 - binary_accuracy: 0.3566 - val_loss: 1.1856 - val_binary_accuracy: 0.2258\n",
      "Epoch 114/150\n",
      "272/272 [==============================] - 0s 239us/step - loss: 1.1205 - binary_accuracy: 0.3621 - val_loss: 1.2434 - val_binary_accuracy: 0.2419\n",
      "Epoch 115/150\n",
      "272/272 [==============================] - 0s 259us/step - loss: 1.1230 - binary_accuracy: 0.3438 - val_loss: 1.1837 - val_binary_accuracy: 0.2581\n",
      "Epoch 116/150\n",
      "272/272 [==============================] - 0s 258us/step - loss: 1.1208 - binary_accuracy: 0.3364 - val_loss: 1.1660 - val_binary_accuracy: 0.2581\n",
      "Epoch 117/150\n",
      "272/272 [==============================] - 0s 259us/step - loss: 1.1163 - binary_accuracy: 0.3640 - val_loss: 1.1831 - val_binary_accuracy: 0.2581\n",
      "Epoch 118/150\n",
      "272/272 [==============================] - 0s 230us/step - loss: 1.1229 - binary_accuracy: 0.3346 - val_loss: 1.1700 - val_binary_accuracy: 0.2742\n",
      "Epoch 119/150\n",
      "272/272 [==============================] - 0s 268us/step - loss: 1.1164 - binary_accuracy: 0.3364 - val_loss: 1.1565 - val_binary_accuracy: 0.2742\n",
      "Epoch 120/150\n",
      "272/272 [==============================] - 0s 252us/step - loss: 1.1196 - binary_accuracy: 0.3419 - val_loss: 1.1690 - val_binary_accuracy: 0.3065\n",
      "Epoch 121/150\n",
      "272/272 [==============================] - 0s 261us/step - loss: 1.1160 - binary_accuracy: 0.3566 - val_loss: 1.1462 - val_binary_accuracy: 0.2903\n",
      "Epoch 122/150\n",
      "272/272 [==============================] - 0s 218us/step - loss: 1.1167 - binary_accuracy: 0.3493 - val_loss: 1.1678 - val_binary_accuracy: 0.2742\n",
      "Epoch 123/150\n",
      "272/272 [==============================] - 0s 236us/step - loss: 1.1176 - binary_accuracy: 0.3566 - val_loss: 1.1406 - val_binary_accuracy: 0.2903\n",
      "Epoch 124/150\n",
      "272/272 [==============================] - 0s 209us/step - loss: 1.1153 - binary_accuracy: 0.3511 - val_loss: 1.1488 - val_binary_accuracy: 0.2581\n",
      "Epoch 125/150\n",
      "272/272 [==============================] - 0s 205us/step - loss: 1.1157 - binary_accuracy: 0.3474 - val_loss: 1.1734 - val_binary_accuracy: 0.2742\n",
      "Epoch 126/150\n",
      "272/272 [==============================] - 0s 212us/step - loss: 1.1203 - binary_accuracy: 0.3603 - val_loss: 1.1366 - val_binary_accuracy: 0.2581\n",
      "Epoch 127/150\n",
      "272/272 [==============================] - 0s 277us/step - loss: 1.1182 - binary_accuracy: 0.3529 - val_loss: 1.1220 - val_binary_accuracy: 0.2581\n",
      "Epoch 128/150\n",
      "272/272 [==============================] - 0s 246us/step - loss: 1.1152 - binary_accuracy: 0.3566 - val_loss: 1.1630 - val_binary_accuracy: 0.1935\n",
      "Epoch 129/150\n",
      "272/272 [==============================] - 0s 259us/step - loss: 1.1132 - binary_accuracy: 0.3456 - val_loss: 1.1510 - val_binary_accuracy: 0.2742\n",
      "Epoch 130/150\n",
      "272/272 [==============================] - 0s 262us/step - loss: 1.1166 - binary_accuracy: 0.3364 - val_loss: 1.1520 - val_binary_accuracy: 0.2742\n",
      "Epoch 131/150\n",
      "272/272 [==============================] - 0s 259us/step - loss: 1.1191 - binary_accuracy: 0.3603 - val_loss: 1.1626 - val_binary_accuracy: 0.2581\n",
      "Epoch 132/150\n",
      "272/272 [==============================] - 0s 224us/step - loss: 1.1150 - binary_accuracy: 0.3585 - val_loss: 1.1558 - val_binary_accuracy: 0.2258\n",
      "Epoch 133/150\n",
      "272/272 [==============================] - 0s 227us/step - loss: 1.1145 - binary_accuracy: 0.3548 - val_loss: 1.1501 - val_binary_accuracy: 0.2581\n",
      "Epoch 134/150\n",
      "272/272 [==============================] - 0s 219us/step - loss: 1.1108 - binary_accuracy: 0.3585 - val_loss: 1.1403 - val_binary_accuracy: 0.2258\n",
      "Epoch 135/150\n",
      "272/272 [==============================] - 0s 215us/step - loss: 1.1138 - binary_accuracy: 0.3548 - val_loss: 1.1250 - val_binary_accuracy: 0.2419\n",
      "Epoch 136/150\n",
      "272/272 [==============================] - 0s 244us/step - loss: 1.1157 - binary_accuracy: 0.3474 - val_loss: 1.1390 - val_binary_accuracy: 0.1935\n",
      "Epoch 137/150\n",
      "272/272 [==============================] - 0s 243us/step - loss: 1.1167 - binary_accuracy: 0.3603 - val_loss: 1.1374 - val_binary_accuracy: 0.2419\n",
      "Epoch 138/150\n",
      "272/272 [==============================] - 0s 302us/step - loss: 1.1171 - binary_accuracy: 0.3676 - val_loss: 1.1336 - val_binary_accuracy: 0.2742\n",
      "Epoch 139/150\n",
      "272/272 [==============================] - 0s 269us/step - loss: 1.1130 - binary_accuracy: 0.3548 - val_loss: 1.1637 - val_binary_accuracy: 0.2258\n",
      "Epoch 140/150\n",
      "272/272 [==============================] - 0s 318us/step - loss: 1.1116 - binary_accuracy: 0.3474 - val_loss: 1.1631 - val_binary_accuracy: 0.2419\n",
      "Epoch 141/150\n",
      "272/272 [==============================] - 0s 302us/step - loss: 1.1102 - binary_accuracy: 0.3493 - val_loss: 1.1525 - val_binary_accuracy: 0.2097\n",
      "Epoch 142/150\n",
      "272/272 [==============================] - 0s 254us/step - loss: 1.1135 - binary_accuracy: 0.3511 - val_loss: 1.1453 - val_binary_accuracy: 0.3065\n",
      "Epoch 143/150\n",
      "272/272 [==============================] - 0s 270us/step - loss: 1.1220 - binary_accuracy: 0.3603 - val_loss: 1.1724 - val_binary_accuracy: 0.2419\n",
      "Epoch 144/150\n",
      "272/272 [==============================] - 0s 288us/step - loss: 1.1155 - binary_accuracy: 0.3364 - val_loss: 1.1624 - val_binary_accuracy: 0.2097\n",
      "Epoch 145/150\n",
      "272/272 [==============================] - 0s 264us/step - loss: 1.1150 - binary_accuracy: 0.3438 - val_loss: 1.1414 - val_binary_accuracy: 0.2097\n",
      "Epoch 146/150\n",
      "272/272 [==============================] - 0s 250us/step - loss: 1.1160 - binary_accuracy: 0.3548 - val_loss: 1.1439 - val_binary_accuracy: 0.2097\n",
      "Epoch 147/150\n",
      "272/272 [==============================] - 0s 247us/step - loss: 1.1143 - binary_accuracy: 0.3640 - val_loss: 1.1377 - val_binary_accuracy: 0.2419\n",
      "Epoch 148/150\n",
      "272/272 [==============================] - 0s 197us/step - loss: 1.1102 - binary_accuracy: 0.3493 - val_loss: 1.1375 - val_binary_accuracy: 0.2419\n",
      "Epoch 149/150\n",
      "272/272 [==============================] - 0s 254us/step - loss: 1.1125 - binary_accuracy: 0.3566 - val_loss: 1.1521 - val_binary_accuracy: 0.2581\n",
      "Epoch 150/150\n",
      "272/272 [==============================] - 0s 232us/step - loss: 1.1198 - binary_accuracy: 0.3493 - val_loss: 1.1257 - val_binary_accuracy: 0.2581\n",
      "76/76 [==============================] - 0s 106us/step\n",
      "\n",
      "binary_accuracy: 44.74%\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(X_train, Y_train, epochs=150, batch_size=10, validation_split=0.1)\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"191pt\" viewBox=\"0.00 0.00 226.00 191.00\" width=\"226pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 187)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-187 222,-187 222,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139957907338464 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139957907338464</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 218,-182.5 218,-146.5 0,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"109\" y=\"-160.8\">dense_29_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139957907339136 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139957907339136</title>\n",
       "<polygon fill=\"none\" points=\"40.5,-73.5 40.5,-109.5 177.5,-109.5 177.5,-73.5 40.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"109\" y=\"-87.8\">dense_29: Dense</text>\n",
       "</g>\n",
       "<!-- 139957907338464&#45;&gt;139957907339136 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139957907338464-&gt;139957907339136</title>\n",
       "<path d=\"M109,-146.313C109,-138.289 109,-128.547 109,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"112.5,-119.529 109,-109.529 105.5,-119.529 112.5,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139957907297056 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139957907297056</title>\n",
       "<polygon fill=\"none\" points=\"40.5,-0.5 40.5,-36.5 177.5,-36.5 177.5,-0.5 40.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"109\" y=\"-14.8\">dense_30: Dense</text>\n",
       "</g>\n",
       "<!-- 139957907339136&#45;&gt;139957907297056 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139957907339136-&gt;139957907297056</title>\n",
       "<path d=\"M109,-73.3129C109,-65.2895 109,-55.5475 109,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"112.5,-46.5288 109,-36.5288 105.5,-46.5289 112.5,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 110us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6956214716559962, 0.4473684226211749]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.evaluate(X_test, Y_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate predictions\n",
    "predictions = model.predict(X_test)\n",
    "result = np.matrix.round(predictions)\n",
    "pprint(result == Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
